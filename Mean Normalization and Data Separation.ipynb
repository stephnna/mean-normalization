{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2780  558 1639 ...  253 3536  806]\n",
      " [3947 1689 2189 ... 4455 3068 1766]\n",
      " [ 911 2341 1364 ... 1565 3959 1093]\n",
      " ...\n",
      " [4880 4050 3474 ... 4520 2041  309]\n",
      " [2427 2308 1001 ... 3535 3072  688]\n",
      " [1774  241 4136 ...  193 1320 3024]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01363401581512552\n",
      "-0.03651740150317353\n",
      "0.11440547011609128\n"
     ]
    }
   ],
   "source": [
    "# # Print the average of all the values of X_norm\n",
    "# print(X_norm.mean())\n",
    "\n",
    "\n",
    "# # Print the average of the minimum value in each column of X_norm\n",
    "# print(X_norm.mean(axis=0).min())\n",
    "\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.mean(axis=0).max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[832 300 410 304 202 645 795 274 930 226 846 167 239 914  59 942  95 484\n",
      " 950 526 498 687 530 509 351 837 267 149 842 139 313 581 702 533   3 541\n",
      " 946 807 450  38 726 988 195 121 691 909 894 635 340 841 373 684 265 763\n",
      " 893 993 296 176 804 955 443 454 416 845 905 618 129 891 433 507 377 113\n",
      " 515 862 278 979 548 882 103  12 912 228 782  27 428 574 193  64 705 473\n",
      " 639 727 714 822 282 551 688 939 209 158 713  88 579 562 136 186 965 414\n",
      " 232 570 722 479 883 221 741 774 809  33 248 583 928 500 447 405 601 438\n",
      " 319 275 423 557  37 118 598 831  57  46 758 651 686 483 393 397 696  19\n",
      " 678 952 204 597  40 307 730 543 192 791 437  70 549 823 870 720 875 703\n",
      "  84 126 398 615 153 641 162 577 830  73 889 518  22 522 789 528 649 712\n",
      " 128 145  74 317 816 652 906  85 259 254 931 732 117 948 244 724 706 346\n",
      " 568  55 986 821 375 658 429 974  24 588  36 107 512 442 637  76 941 867\n",
      "  80 833 944 838 342 787 144 417 499 987 470 753 323 576 390 735 879 173\n",
      " 237 911 172 591 602 331 638 130 693 755 779 471 527 182 418 788 600 334\n",
      " 970 825 496 827 704 155 936 627 991 759 402 910  13 553 178 247 227  31\n",
      " 345 636 170 769 934 475 668 431 385 707 746 701 365 366 778 299 502 925\n",
      " 829 235 253 744 625 159 105 329 305 885 664  51 212 801 563 683 594 567\n",
      " 474 246 482 770 234 547 101 191 196 865  75 401  72  58 997 387   7 633\n",
      "  10 127 738 895 728 238 432 808   0  90 516 485 306 122  52 281 892 985\n",
      " 362 560 197 908  96 890 391 992 536 785 675 112 544 478 337 257 902 301\n",
      " 851   1   4 731  87 644 486 962 915 332 255 571 682  98 327 408 298  94\n",
      " 225 491 869 460 175 320 877  15 740 367 161 677 177 411 634 315  53 612\n",
      " 781 344 592 663 671 665 943 968 477 503 213 621 790 858 853 490 271 813\n",
      " 692 288 404 303 497 606 918 864 349 729 872 924 356 754 643 164 920 220\n",
      " 550 957 150 586 666 115  41 283 860 457 415 933 631  44 529 120 546  45\n",
      " 626 694 926 211 780 916   6  49 852 219 884 888 880 519 383 322 187 617\n",
      " 427 966  47 260 469 736 223 495  78 266  23 321 715 394 359 953 501 284\n",
      " 291 403  25 290 188 849 657 978 152  97 564 100 535 878 611 263 990 140\n",
      " 839  99 559 976 378 506 656 680 919 374 742 552 566 131 464 207 355 264\n",
      " 245 672 185 435 513 250 352 605 133 817 268 596 236 262 679 660 335 214\n",
      " 311 805 695 147 828 458 667 371 711 971 873 886 989 607 578 293 493 148\n",
      " 716 690 216 360  39 580 558 318 587 977 661 525 419 863 573 857 455 363\n",
      " 783 814 174 132 396 370 747 294 681 407  29 389 708 350 861 764 111 614\n",
      " 203  81 376 963 604 181 459 776  16 699 584 487 146  71 289 771 505 674\n",
      " 710 761 492  69 793 850 772 921 138 183 739  93 521 310 996 961 745 481\n",
      " 876 620 343 240 981 422 241 632 913 757 467 898 803 659 983 840 595 347\n",
      " 798 935 361 777 208 514 843  83 468 806 958 106 430 184 426 648  79 937\n",
      " 676 874 653  18 200 368 775  14 743 210 556 511 286 326 348 448  66 964\n",
      " 163 251 258 534 292 388 380  86 242 314  11 593  50 273 650  56 654 189\n",
      " 700 951 554 582 646 623 670 451 312 116 984 357 995  68  65 662  21 453\n",
      " 881 142 425 465 406 922 545 171   2 472 157 179 269 762 590 907 689 463\n",
      " 975 480 673 119 520 229 297 903 947 489 818 949 619 285 353 973  20 954\n",
      " 569 980 392 859  26 709  67 135 765 810 143 372 494 725 110   9 169 444\n",
      " 243 369 555 585 233 354 124  48 538 280 938 194 215  42 647 218 230 819\n",
      " 897 768 956  60 104 205  63 277 796 386 409 773 899 752 539 384 542 461\n",
      " 108 927 517 767 434 868 599 224 249 871 572 824 412 134 160 302 488 445\n",
      " 628 733 452 439 749 336 421 436 561 256 540  30 866 575 847 381 854  43\n",
      " 510 165 737 295 424 217 324 279 917 998  17 698 123 751 395 630 750 820\n",
      " 929  82 341 800 399 855  91 940  28 622 748 896 358 125  62 565 608 792\n",
      " 836 168   8  92 932 328 156 441 231 201 969 400 537 887 844 523 812  54\n",
      " 901 616 466 834 198 154 102 959 766 669 904 784 603 797 856 141  89 613\n",
      " 799   5 685  77 718  35 815 697 456 900  61 994  34 440 137 504 446 382\n",
      " 923 982 760 835 826 276 723 655 624 379 734 180 811 309 151 109 261 802\n",
      " 508 166 199 270 206 190 272 325 609 524 476 330 333 999 719 756 848 721\n",
      " 967 972 420 222 413 945 462 364 629 449 642 287 308  32 786 339 794 114\n",
      " 316 717 532 252 531 640 589 960 610 338]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600]]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800]] \n",
    "\n",
    "# # Create a Test Set\n",
    "X_test = X_norm[row_indices[800:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
